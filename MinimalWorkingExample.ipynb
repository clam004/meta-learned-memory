{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.version 1.7.0\n",
      "torch.cuda.is_available() True\n",
      "torch.cuda.device_count() 2\n"
     ]
    }
   ],
   "source": [
    "import math, copy, sys, logging, json, time, random, os, string, pickle, re\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.TransformerComponents import Transformer\n",
    "from modules.Vocabulary import Vocab\n",
    "from modules.MetaLearnNeuralMemory import MNMp\n",
    "from modules.LoadTrainSave import save_model, load_model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(0) \n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print('torch.version', torch.__version__)\n",
    "print('torch.cuda.is_available()', torch.cuda.is_available())\n",
    "print('torch.cuda.device_count()', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Working Example\n",
    "\n",
    "This notebook serves as a minimal working example of Meta-Learned Nerual Memory Chatbot (MNMC). The Teacher teaches a simple conversational lesson, \"when I tell you a name, remember my name, when I ask you want my name is, tell me what my name is, if I tell you I have a different name, memorize that new name, when I ask you what my name is, tell me the most recent name I told you\" \n",
    "\n",
    "# Why is this special?\n",
    "\n",
    "Seems like a somewhat mundane task, however, the mechanism by which it is accomplished is what is profound. The \"name\" is not stored in any kind of traditional database or data structure, but rather has been stored in the distributed, aka, shared, weights of a neural network. No new row or element is added to a table or array when the name is remembered, instead the values of a finite set of weights is adjusted. \n",
    "\n",
    "# Explaination\n",
    "\n",
    "Here we show an end to end, albeit minimal, example, the subsequent notebooks will explain Metalearned Nerual memory and how we have combined this with the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(): \n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        \n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.vocab.string2embedding(\"my name is, hi. what is my name? its\")\n",
    "        \n",
    "        self.name_list = [\n",
    "                          'vicki', 'carson', 'melissa', 'salvador', \n",
    "                          'force', 'sky', 'zen', 'adam'\n",
    "                         ]\n",
    "\n",
    "    def random_name(self,):\n",
    "        \"\"\" Generate a random string of fixed length \"\"\"\n",
    "        return random.choice(self.name_list)\n",
    "    \n",
    "    def repeat(self, batch_size):\n",
    "        \n",
    "        self.mynameis = self.vocab.string2tensor(\"my name is\")\n",
    "        self.hi = self.vocab.string2tensor(\"hi\")\n",
    "        self.whatmyname = self.vocab.string2tensor(\"what is my name?\")\n",
    "        self.its = self.vocab.string2tensor(\"its\")\n",
    "\n",
    "        self.mynameis = self.mynameis.repeat(batch_size,1)\n",
    "        self.hi = self.hi.repeat(batch_size,1)\n",
    "        self.whatmyname = self.whatmyname.repeat(batch_size,1)\n",
    "        self.its = self.its.repeat(batch_size,1)\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        \n",
    "        self.repeat(batch_size)\n",
    "        \n",
    "        newnames = \"\"\n",
    "        for n in range(batch_size):\n",
    "            newnames += \" \" + self.random_name()\n",
    "            \n",
    "        self.vocab.string2embedding(newnames)\n",
    "        \n",
    "        self.names = self.vocab.string2tensor(newnames).T\n",
    "\n",
    "        self.intro = torch.cat((self.mynameis, self.names),dim=1)\n",
    "        self.introtarget = torch.cat((self.hi, self.names),dim=1)\n",
    "        self.yournameis = torch.cat((self.its, self.names),dim=1)\n",
    "        \n",
    "        return self.intro, self.introtarget, self.whatmyname, self.yournameis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of the training data outputted from the teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'my': 4, 'name': 5, 'is': 6, ',': 7, 'hi': 8, '.': 9, 'what': 10, '?': 11, 'its': 12}\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(emb_dim=32)\n",
    "teacher = Teacher(vocab)\n",
    "\n",
    "print(vocab.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'my': 4, 'name': 5, 'is': 6, ',': 7, 'hi': 8, '.': 9, 'what': 10, '?': 11, 'its': 12, 'zen': 13, 'vicki': 14, 'force': 15}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "intro, introtarget, whatmyname, yournameis = teacher.get_batch(batch_size)\n",
    "\n",
    "print(vocab.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6, 13],\n",
       "        [ 4,  5,  6, 13],\n",
       "        [ 4,  5,  6, 14],\n",
       "        [ 4,  5,  6, 15]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro # my name is <new token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 13],\n",
       "        [ 8, 13],\n",
       "        [ 8, 14],\n",
       "        [ 8, 15]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introtarget # hi <new token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6,  4,  5, 11],\n",
       "        [10,  6,  4,  5, 11],\n",
       "        [10,  6,  4,  5, 11],\n",
       "        [10,  6,  4,  5, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatmyname # what is my name ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 13],\n",
       "        [12, 13],\n",
       "        [12, 14],\n",
       "        [12, 15]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yournameis # its <new token>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Chatbot (Bot)\n",
    "\n",
    "With built in memory unit, training unit (teacher forcing) and chatting unit (string2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dim, n_layers, heads, dropout, vocab):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.sos_tok = torch.LongTensor([[self.vocab.word2index[\"<SOS>\"]]]) \n",
    "        self.eos_tok = torch.LongTensor([[self.vocab.word2index[\"<EOS>\"]]]) \n",
    "        \n",
    "        self.encodeInput = Transformer(emb_dim, n_layers, heads, dropout)\n",
    "        self.encodeEncoding = Transformer(emb_dim, n_layers, heads, dropout)\n",
    "        self.decodeEncoding = Transformer(emb_dim, n_layers, heads, dropout)\n",
    "\n",
    "        self.mnm = MNMp(emb_dim, heads)\n",
    "        \n",
    "        self.context_vec = None\n",
    "        \n",
    "    def memory_utils(self, batch_size):\n",
    "\n",
    "        if self.context_vec is None:\n",
    "            cntxt_seq_len = 1\n",
    "            self.context_vec = torch.randn(batch_size, cntxt_seq_len, self.emb_dim)\n",
    "            \n",
    "        if self.context_vec.shape[0] > batch_size:\n",
    "            self.context_vec = self.context_vec[0,:,:]\n",
    "            \n",
    "        if self.context_vec.shape[0] < batch_size:\n",
    "            self.context_vec = self.context_vec[0,:,:].repeat(batch_size, 1, 1)\n",
    "    \n",
    "        self.context_vec = self.context_vec.detach()\n",
    "        self.mnm.memfunc.detach_mem()\n",
    "        \n",
    "    def forward(self, in_toks, in_mask, out_toks, out_mask):\n",
    "        \n",
    "        self.memory_utils(batch_size = in_toks.shape[0])\n",
    "        \n",
    "        in_vecs = self.vocab.embedding(in_toks)\n",
    "        out_vec = self.vocab.embedding(out_toks)\n",
    "\n",
    "        self.context_vec, rcl, rcli = self.mnm(self.context_vec)\n",
    "        encin_vec = self.encodeInput(in_vecs, in_mask, self.context_vec, None)\n",
    "        self.context_vec = self.encodeEncoding(self.context_vec, None, encin_vec, None)\n",
    "        \n",
    "        dout = self.decodeEncoding(out_vec, out_mask, encin_vec, in_mask)\n",
    "        \n",
    "        return dout, rcl, rcli\n",
    "    \n",
    "    def teacher_forcing(self, src, trg):\n",
    "        \n",
    "        self.train()\n",
    "        trg_start = torch.cat((self.sos_tok.repeat(trg.shape[0],1), trg),dim=1)\n",
    "        trg_end = torch.cat((trg, self.eos_tok.repeat(trg.shape[0],1)),dim=1)\n",
    "        src_mask = (src != self.vocab.word2index[\"<PAD>\"]).unsqueeze(-2)\n",
    "        trg_mask = (trg_end != self.vocab.word2index[\"<PAD>\"]).unsqueeze(-2)\n",
    "        \n",
    "        seq_len = trg_start.size(1) \n",
    "        np_mask = np.triu(np.ones((1,seq_len,seq_len)),k=1).astype('uint8')\n",
    "        np_mask =  torch.from_numpy(np_mask) == 0\n",
    "        \n",
    "        if trg.is_cuda:\n",
    "            np_mask = np_mask.cuda()\n",
    "            \n",
    "        trg_mask = trg_mask & np_mask\n",
    "        \n",
    "        out_vecs, rcl, rcli = self.forward(src, src_mask, trg_start, trg_mask)\n",
    "        \n",
    "        return out_vecs, trg_end, rcl, rcli\n",
    "    \n",
    "    def string2string(self, input_string, maxlen = 20):\n",
    "        \n",
    "        self.eval()\n",
    "        in_toks = self.vocab.string2tensor(input_string)\n",
    "        in_vecs = self.vocab.embedding(in_toks)\n",
    "        \n",
    "        self.memory_utils(batch_size=in_toks.shape[0])\n",
    "        \n",
    "        self.context_vec, rcl, rcli = self.mnm(self.context_vec)\n",
    "        encin_vec = self.encodeInput(in_vecs, None, self.context_vec, None)\n",
    "        self.context_vec = self.encodeEncoding(self.context_vec, None, encin_vec, None)\n",
    "        \n",
    "        decode_toks = self.sos_tok\n",
    "        \n",
    "        for pos in range(maxlen):\n",
    "            \n",
    "            decode_vecs = self.vocab.embedding(decode_toks)\n",
    "            dout = self.decodeEncoding(decode_vecs, None, encin_vec, None)\n",
    "            vocabdist = self.vocab.emb2vocab(dout)\n",
    "            next_toks = torch.argmax(vocabdist, dim=2)\n",
    "            decode_toks = torch.cat((decode_toks, next_toks[:,-1].unsqueeze(0)), dim=1) \n",
    "            \n",
    "            if next_toks[:,-1] == self.eos_tok.squeeze(0):\n",
    "                \n",
    "                toks = decode_toks[0][1:-1].data.cpu().numpy()\n",
    "                de_str = ' '.join([self.vocab.index2word[int(tok)] for tok in toks])\n",
    "\n",
    "                return de_str\n",
    "            \n",
    "        toks = decode_toks[0].data.cpu().numpy()\n",
    "        de_str = ' '.join([self.vocab.index2word[tok] for tok in toks])\n",
    "        return de_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the vocab, model and teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'my': 4, 'name': 5, 'is': 6, ',': 7, 'hi': 8, '.': 9, 'what': 10, '?': 11, 'its': 12}\n"
     ]
    }
   ],
   "source": [
    "emb_dim, n_layers, heads, dropout = 32, 2, 2, 0.05\n",
    "\n",
    "vocab = Vocab(emb_dim)\n",
    "model = Bot(emb_dim, n_layers, heads, dropout, vocab)\n",
    "teacher = Teacher(model.vocab)\n",
    "\n",
    "print(model.vocab.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model...\n",
      "mean accuracy 0.8333 celoss 0.7037 rcloss 0.003307 d_rcloss 0.0399 training progress 0.0 learning rate [0.01]\n",
      "mean accuracy 0.8125 celoss 0.6809 rcloss 0.001418 d_rcloss 0.0316 training progress 0.0516 learning rate [0.01]\n",
      "mean accuracy 0.8247 celoss 0.4783 rcloss 0.000987 d_rcloss 0.0287 training progress 0.1031 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8359 celoss 0.4284 rcloss 0.001411 d_rcloss 0.0389 training progress 0.1547 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8365 celoss 0.573 rcloss 0.001712 d_rcloss 0.0359 training progress 0.2062 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8403 celoss 0.396 rcloss 0.00096 d_rcloss 0.0352 training progress 0.2578 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8497 celoss 0.324 rcloss 0.001121 d_rcloss 0.0322 training progress 0.3094 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8581 celoss 0.3206 rcloss 0.002734 d_rcloss 0.039 training progress 0.3609 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8628 celoss 0.3572 rcloss 0.001297 d_rcloss 0.0432 training progress 0.4125 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8693 celoss 0.2538 rcloss 0.001107 d_rcloss 0.0384 training progress 0.4641 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8755 celoss 0.3858 rcloss 0.001014 d_rcloss 0.0395 training progress 0.5156 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8896 celoss 0.1811 rcloss 0.001375 d_rcloss 0.0366 training progress 0.5672 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8932 celoss 0.4477 rcloss 0.001045 d_rcloss 0.0401 training progress 0.6188 learning rate [0.01]\n",
      "mean accuracy 0.8927 celoss 0.4071 rcloss 0.001989 d_rcloss 0.0391 training progress 0.6703 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8953 celoss 0.362 rcloss 0.001175 d_rcloss 0.0382 training progress 0.7219 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.901 celoss 0.2478 rcloss 0.000655 d_rcloss 0.0376 training progress 0.7734 learning rate [0.0099]\n",
      "Saving Model...\n",
      "mean accuracy 0.9021 celoss 0.1937 rcloss 0.001824 d_rcloss 0.0368 training progress 0.825 learning rate [0.0099]\n",
      "mean accuracy 0.9005 celoss 0.2535 rcloss 0.002087 d_rcloss 0.0415 training progress 0.8766 learning rate [0.0099]\n",
      "Saving Model...\n",
      "mean accuracy 0.9026 celoss 0.2526 rcloss 0.001093 d_rcloss 0.0364 training progress 0.9281 learning rate [0.0099]\n",
      "mean accuracy 0.9005 celoss 0.2378 rcloss 0.001078 d_rcloss 0.0412 training progress 0.9797 learning rate [0.0099]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9900b6320>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_batches = 64*10\n",
    "best_acc = 0\n",
    "lamda = 8\n",
    "batch_size = 64\n",
    "learning_rate = 0.01 #0.001\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate,betas=(0.9, 0.98),eps=1e-9)\n",
    "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',factor=0.99,patience=100)\n",
    "\n",
    "loss_all_list = []\n",
    "rcloss_all_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for batch in range(total_batches):\n",
    "    \n",
    "    intro, introtarget, whatmyname, yournameis = teacher.get_batch(batch_size)\n",
    "    \n",
    "    out_vecs, trg_end, rcl, rcli = model.teacher_forcing(intro, introtarget)\n",
    "    \n",
    "    vocab_logits = model.vocab.emb2vocab(out_vecs)\n",
    "    \n",
    "    predictions = vocab_logits.view(-1, vocab_logits.size(-1))\n",
    "    \n",
    "    target = trg_end.view(-1)\n",
    "\n",
    "    batch_loss = F.cross_entropy(predictions, target, \n",
    "                                 ignore_index = model.vocab.word2index[\"<PAD>\"])\n",
    "\n",
    "    reconstruction_loss = lamda*rcl\n",
    "    \n",
    "    ################# Next Part of Conversation ########################\n",
    "    \n",
    "    out_vecs, trg_end, rcl, rcli = model.teacher_forcing(whatmyname, yournameis)\n",
    "    \n",
    "    vocab_logits = model.vocab.emb2vocab(out_vecs)\n",
    "\n",
    "    predictions = vocab_logits.view(-1, vocab_logits.size(-1))\n",
    "    \n",
    "    target = trg_end.view(-1)\n",
    "    \n",
    "    acc = accuracy_score(target, torch.argmax(predictions, dim=1))\n",
    "\n",
    "    batch_loss += F.cross_entropy(predictions, target, \n",
    "                                 ignore_index = model.vocab.word2index[\"<PAD>\"])\n",
    "    \n",
    "    reconstruction_loss += lamda*rcl\n",
    "    conversation_loss = batch_loss + reconstruction_loss\n",
    "    \n",
    "    scheduler.step(conversation_loss)\n",
    "    optimizer.zero_grad()\n",
    "    conversation_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch % int(total_batches/20 + 1) == 0:\n",
    "        \n",
    "        loss_all_list.append(conversation_loss.float().item())\n",
    "        rcloss_all_list.append(reconstruction_loss.float().item())\n",
    "        accuracy_list.append(acc)\n",
    "        mean_accuracy = np.mean(accuracy_list[-10:])\n",
    "\n",
    "        if mean_accuracy > best_acc:\n",
    "            print('Saving Model...')\n",
    "            best_acc = mean_accuracy\n",
    "            \n",
    "            pickle.dump(model.vocab.word2index,open(\"modelstate/word2index.p\",\"wb\"))\n",
    "            pickle.dump(model.vocab.index2word,open(\"modelstate/index2word.p\",\"wb\"))\n",
    "            pickle.dump(model.vocab.emb2vocab.weight,open(\"modelstate/emb2vocab.weight.p\",\"wb\"))\n",
    "            pickle.dump(model.vocab.embedding.weight,open(\"modelstate/embedding.weight.p\",\"wb\"))\n",
    "            pickle.dump(model.context_vec,open(\"modelstate/context_vec.p\",\"wb\"))\n",
    "            pickle.dump(model.mnm.memfunc.Ws,open(\"modelstate/Ws.p\",\"wb\"))\n",
    "            save_model(model,\"modelstate/task.pth\")\n",
    "            \n",
    "        print(\"mean accuracy\", round(mean_accuracy,4), \n",
    "              \"celoss\", round(batch_loss.float().item(),4), \n",
    "              \"rcloss\", round(reconstruction_loss.float().item(),6), \n",
    "              \"d_rcloss\", round((rcli - rcl).float().item(),4),\n",
    "              \"training progress\", round(batch/total_batches,4),\n",
    "              \"learning rate\", scheduler._last_lr)\n",
    "            \n",
    "        if mean_accuracy > 0.97:\n",
    "            break\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "fig.suptitle('Training Curves')\n",
    "ax1.set(xlabel='epochs', ylabel='train loss')\n",
    "ax2.set(xlabel='epochs', ylabel='reconstr loss')\n",
    "ax3.set(xlabel='epochs', ylabel='accuracy')\n",
    "ax1.plot(loss_all_list, label='train loss')\n",
    "ax2.plot(rcloss_all_list, label='reconstrunction loss')\n",
    "ax3.plot(accuracy_list, label='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the names of all the trainable parameters, aka, weights in this model. there are a few other parameters that are not in the computational graph of pytorch, which is why there are other saved files to be saved and re-loaded besides `save_model(model,\"modelstate/task.pth\")` such as the embeddings, vocabulary dictionary, the vector that stores the last memory and the matrices that store the memories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab.embedding.weight\n",
      "vocab.emb2vocab.weight\n",
      "encodeInput.encodelayers.0.norm_1.alpha\n",
      "encodeInput.encodelayers.0.norm_1.bias\n",
      "encodeInput.encodelayers.0.attn.q_linear.weight\n",
      "encodeInput.encodelayers.0.attn.q_linear.bias\n",
      "encodeInput.encodelayers.0.attn.k_linear.weight\n",
      "encodeInput.encodelayers.0.attn.k_linear.bias\n",
      "encodeInput.encodelayers.0.attn.v_linear.weight\n",
      "encodeInput.encodelayers.0.attn.v_linear.bias\n",
      "encodeInput.encodelayers.0.attn.out.weight\n",
      "encodeInput.encodelayers.0.attn.out.bias\n",
      "encodeInput.encodelayers.0.norm_2.alpha\n",
      "encodeInput.encodelayers.0.norm_2.bias\n",
      "encodeInput.encodelayers.0.ff.linear_1.weight\n",
      "encodeInput.encodelayers.0.ff.linear_1.bias\n",
      "encodeInput.encodelayers.0.ff.linear_2.weight\n",
      "encodeInput.encodelayers.0.ff.linear_2.bias\n",
      "encodeInput.encodelayers.1.norm_1.alpha\n",
      "encodeInput.encodelayers.1.norm_1.bias\n",
      "encodeInput.encodelayers.1.attn.q_linear.weight\n",
      "encodeInput.encodelayers.1.attn.q_linear.bias\n",
      "encodeInput.encodelayers.1.attn.k_linear.weight\n",
      "encodeInput.encodelayers.1.attn.k_linear.bias\n",
      "encodeInput.encodelayers.1.attn.v_linear.weight\n",
      "encodeInput.encodelayers.1.attn.v_linear.bias\n",
      "encodeInput.encodelayers.1.attn.out.weight\n",
      "encodeInput.encodelayers.1.attn.out.bias\n",
      "encodeInput.encodelayers.1.norm_2.alpha\n",
      "encodeInput.encodelayers.1.norm_2.bias\n",
      "encodeInput.encodelayers.1.ff.linear_1.weight\n",
      "encodeInput.encodelayers.1.ff.linear_1.bias\n",
      "encodeInput.encodelayers.1.ff.linear_2.weight\n",
      "encodeInput.encodelayers.1.ff.linear_2.bias\n",
      "encodeInput.decodelayers.0.norm_1.alpha\n",
      "encodeInput.decodelayers.0.norm_1.bias\n",
      "encodeInput.decodelayers.0.norm_2.alpha\n",
      "encodeInput.decodelayers.0.norm_2.bias\n",
      "encodeInput.decodelayers.0.norm_3.alpha\n",
      "encodeInput.decodelayers.0.norm_3.bias\n",
      "encodeInput.decodelayers.0.attn_1.q_linear.weight\n",
      "encodeInput.decodelayers.0.attn_1.q_linear.bias\n",
      "encodeInput.decodelayers.0.attn_1.k_linear.weight\n",
      "encodeInput.decodelayers.0.attn_1.k_linear.bias\n",
      "encodeInput.decodelayers.0.attn_1.v_linear.weight\n",
      "encodeInput.decodelayers.0.attn_1.v_linear.bias\n",
      "encodeInput.decodelayers.0.attn_1.out.weight\n",
      "encodeInput.decodelayers.0.attn_1.out.bias\n",
      "encodeInput.decodelayers.0.attn_2.q_linear.weight\n",
      "encodeInput.decodelayers.0.attn_2.q_linear.bias\n",
      "encodeInput.decodelayers.0.attn_2.k_linear.weight\n",
      "encodeInput.decodelayers.0.attn_2.k_linear.bias\n",
      "encodeInput.decodelayers.0.attn_2.v_linear.weight\n",
      "encodeInput.decodelayers.0.attn_2.v_linear.bias\n",
      "encodeInput.decodelayers.0.attn_2.out.weight\n",
      "encodeInput.decodelayers.0.attn_2.out.bias\n",
      "encodeInput.decodelayers.0.ff.linear_1.weight\n",
      "encodeInput.decodelayers.0.ff.linear_1.bias\n",
      "encodeInput.decodelayers.0.ff.linear_2.weight\n",
      "encodeInput.decodelayers.0.ff.linear_2.bias\n",
      "encodeInput.decodelayers.1.norm_1.alpha\n",
      "encodeInput.decodelayers.1.norm_1.bias\n",
      "encodeInput.decodelayers.1.norm_2.alpha\n",
      "encodeInput.decodelayers.1.norm_2.bias\n",
      "encodeInput.decodelayers.1.norm_3.alpha\n",
      "encodeInput.decodelayers.1.norm_3.bias\n",
      "encodeInput.decodelayers.1.attn_1.q_linear.weight\n",
      "encodeInput.decodelayers.1.attn_1.q_linear.bias\n",
      "encodeInput.decodelayers.1.attn_1.k_linear.weight\n",
      "encodeInput.decodelayers.1.attn_1.k_linear.bias\n",
      "encodeInput.decodelayers.1.attn_1.v_linear.weight\n",
      "encodeInput.decodelayers.1.attn_1.v_linear.bias\n",
      "encodeInput.decodelayers.1.attn_1.out.weight\n",
      "encodeInput.decodelayers.1.attn_1.out.bias\n",
      "encodeInput.decodelayers.1.attn_2.q_linear.weight\n",
      "encodeInput.decodelayers.1.attn_2.q_linear.bias\n",
      "encodeInput.decodelayers.1.attn_2.k_linear.weight\n",
      "encodeInput.decodelayers.1.attn_2.k_linear.bias\n",
      "encodeInput.decodelayers.1.attn_2.v_linear.weight\n",
      "encodeInput.decodelayers.1.attn_2.v_linear.bias\n",
      "encodeInput.decodelayers.1.attn_2.out.weight\n",
      "encodeInput.decodelayers.1.attn_2.out.bias\n",
      "encodeInput.decodelayers.1.ff.linear_1.weight\n",
      "encodeInput.decodelayers.1.ff.linear_1.bias\n",
      "encodeInput.decodelayers.1.ff.linear_2.weight\n",
      "encodeInput.decodelayers.1.ff.linear_2.bias\n",
      "encodeInput.norm.alpha\n",
      "encodeInput.norm.bias\n",
      "encodeEncoding.encodelayers.0.norm_1.alpha\n",
      "encodeEncoding.encodelayers.0.norm_1.bias\n",
      "encodeEncoding.encodelayers.0.attn.q_linear.weight\n",
      "encodeEncoding.encodelayers.0.attn.q_linear.bias\n",
      "encodeEncoding.encodelayers.0.attn.k_linear.weight\n",
      "encodeEncoding.encodelayers.0.attn.k_linear.bias\n",
      "encodeEncoding.encodelayers.0.attn.v_linear.weight\n",
      "encodeEncoding.encodelayers.0.attn.v_linear.bias\n",
      "encodeEncoding.encodelayers.0.attn.out.weight\n",
      "encodeEncoding.encodelayers.0.attn.out.bias\n",
      "encodeEncoding.encodelayers.0.norm_2.alpha\n",
      "encodeEncoding.encodelayers.0.norm_2.bias\n",
      "encodeEncoding.encodelayers.0.ff.linear_1.weight\n",
      "encodeEncoding.encodelayers.0.ff.linear_1.bias\n",
      "encodeEncoding.encodelayers.0.ff.linear_2.weight\n",
      "encodeEncoding.encodelayers.0.ff.linear_2.bias\n",
      "encodeEncoding.encodelayers.1.norm_1.alpha\n",
      "encodeEncoding.encodelayers.1.norm_1.bias\n",
      "encodeEncoding.encodelayers.1.attn.q_linear.weight\n",
      "encodeEncoding.encodelayers.1.attn.q_linear.bias\n",
      "encodeEncoding.encodelayers.1.attn.k_linear.weight\n",
      "encodeEncoding.encodelayers.1.attn.k_linear.bias\n",
      "encodeEncoding.encodelayers.1.attn.v_linear.weight\n",
      "encodeEncoding.encodelayers.1.attn.v_linear.bias\n",
      "encodeEncoding.encodelayers.1.attn.out.weight\n",
      "encodeEncoding.encodelayers.1.attn.out.bias\n",
      "encodeEncoding.encodelayers.1.norm_2.alpha\n",
      "encodeEncoding.encodelayers.1.norm_2.bias\n",
      "encodeEncoding.encodelayers.1.ff.linear_1.weight\n",
      "encodeEncoding.encodelayers.1.ff.linear_1.bias\n",
      "encodeEncoding.encodelayers.1.ff.linear_2.weight\n",
      "encodeEncoding.encodelayers.1.ff.linear_2.bias\n",
      "encodeEncoding.decodelayers.0.norm_1.alpha\n",
      "encodeEncoding.decodelayers.0.norm_1.bias\n",
      "encodeEncoding.decodelayers.0.norm_2.alpha\n",
      "encodeEncoding.decodelayers.0.norm_2.bias\n",
      "encodeEncoding.decodelayers.0.norm_3.alpha\n",
      "encodeEncoding.decodelayers.0.norm_3.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.q_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.q_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.k_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.k_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.v_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.v_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.out.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.out.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.q_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.q_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.k_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.k_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.v_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.v_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.out.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.out.bias\n",
      "encodeEncoding.decodelayers.0.ff.linear_1.weight\n",
      "encodeEncoding.decodelayers.0.ff.linear_1.bias\n",
      "encodeEncoding.decodelayers.0.ff.linear_2.weight\n",
      "encodeEncoding.decodelayers.0.ff.linear_2.bias\n",
      "encodeEncoding.decodelayers.1.norm_1.alpha\n",
      "encodeEncoding.decodelayers.1.norm_1.bias\n",
      "encodeEncoding.decodelayers.1.norm_2.alpha\n",
      "encodeEncoding.decodelayers.1.norm_2.bias\n",
      "encodeEncoding.decodelayers.1.norm_3.alpha\n",
      "encodeEncoding.decodelayers.1.norm_3.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.q_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.q_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.k_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.k_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.v_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.v_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.out.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.out.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.q_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.q_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.k_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.k_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.v_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.v_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.out.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.out.bias\n",
      "encodeEncoding.decodelayers.1.ff.linear_1.weight\n",
      "encodeEncoding.decodelayers.1.ff.linear_1.bias\n",
      "encodeEncoding.decodelayers.1.ff.linear_2.weight\n",
      "encodeEncoding.decodelayers.1.ff.linear_2.bias\n",
      "encodeEncoding.norm.alpha\n",
      "encodeEncoding.norm.bias\n",
      "decodeEncoding.encodelayers.0.norm_1.alpha\n",
      "decodeEncoding.encodelayers.0.norm_1.bias\n",
      "decodeEncoding.encodelayers.0.attn.q_linear.weight\n",
      "decodeEncoding.encodelayers.0.attn.q_linear.bias\n",
      "decodeEncoding.encodelayers.0.attn.k_linear.weight\n",
      "decodeEncoding.encodelayers.0.attn.k_linear.bias\n",
      "decodeEncoding.encodelayers.0.attn.v_linear.weight\n",
      "decodeEncoding.encodelayers.0.attn.v_linear.bias\n",
      "decodeEncoding.encodelayers.0.attn.out.weight\n",
      "decodeEncoding.encodelayers.0.attn.out.bias\n",
      "decodeEncoding.encodelayers.0.norm_2.alpha\n",
      "decodeEncoding.encodelayers.0.norm_2.bias\n",
      "decodeEncoding.encodelayers.0.ff.linear_1.weight\n",
      "decodeEncoding.encodelayers.0.ff.linear_1.bias\n",
      "decodeEncoding.encodelayers.0.ff.linear_2.weight\n",
      "decodeEncoding.encodelayers.0.ff.linear_2.bias\n",
      "decodeEncoding.encodelayers.1.norm_1.alpha\n",
      "decodeEncoding.encodelayers.1.norm_1.bias\n",
      "decodeEncoding.encodelayers.1.attn.q_linear.weight\n",
      "decodeEncoding.encodelayers.1.attn.q_linear.bias\n",
      "decodeEncoding.encodelayers.1.attn.k_linear.weight\n",
      "decodeEncoding.encodelayers.1.attn.k_linear.bias\n",
      "decodeEncoding.encodelayers.1.attn.v_linear.weight\n",
      "decodeEncoding.encodelayers.1.attn.v_linear.bias\n",
      "decodeEncoding.encodelayers.1.attn.out.weight\n",
      "decodeEncoding.encodelayers.1.attn.out.bias\n",
      "decodeEncoding.encodelayers.1.norm_2.alpha\n",
      "decodeEncoding.encodelayers.1.norm_2.bias\n",
      "decodeEncoding.encodelayers.1.ff.linear_1.weight\n",
      "decodeEncoding.encodelayers.1.ff.linear_1.bias\n",
      "decodeEncoding.encodelayers.1.ff.linear_2.weight\n",
      "decodeEncoding.encodelayers.1.ff.linear_2.bias\n",
      "decodeEncoding.decodelayers.0.norm_1.alpha\n",
      "decodeEncoding.decodelayers.0.norm_1.bias\n",
      "decodeEncoding.decodelayers.0.norm_2.alpha\n",
      "decodeEncoding.decodelayers.0.norm_2.bias\n",
      "decodeEncoding.decodelayers.0.norm_3.alpha\n",
      "decodeEncoding.decodelayers.0.norm_3.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.q_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.q_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.k_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.k_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.v_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.v_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.out.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.out.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.q_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.q_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.k_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.k_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.v_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.v_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.out.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.out.bias\n",
      "decodeEncoding.decodelayers.0.ff.linear_1.weight\n",
      "decodeEncoding.decodelayers.0.ff.linear_1.bias\n",
      "decodeEncoding.decodelayers.0.ff.linear_2.weight\n",
      "decodeEncoding.decodelayers.0.ff.linear_2.bias\n",
      "decodeEncoding.decodelayers.1.norm_1.alpha\n",
      "decodeEncoding.decodelayers.1.norm_1.bias\n",
      "decodeEncoding.decodelayers.1.norm_2.alpha\n",
      "decodeEncoding.decodelayers.1.norm_2.bias\n",
      "decodeEncoding.decodelayers.1.norm_3.alpha\n",
      "decodeEncoding.decodelayers.1.norm_3.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.q_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.q_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.k_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.k_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.v_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.v_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.out.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.out.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.q_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.q_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.k_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.k_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.v_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.v_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.out.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.out.bias\n",
      "decodeEncoding.decodelayers.1.ff.linear_1.weight\n",
      "decodeEncoding.decodelayers.1.ff.linear_1.bias\n",
      "decodeEncoding.decodelayers.1.ff.linear_2.weight\n",
      "decodeEncoding.decodelayers.1.ff.linear_2.bias\n",
      "decodeEncoding.norm.alpha\n",
      "decodeEncoding.norm.bias\n",
      "mnm.control.weight_ih\n",
      "mnm.control.weight_hh\n",
      "mnm.control.bias_ih\n",
      "mnm.control.bias_hh\n",
      "mnm.interaction.weight\n",
      "mnm.interaction.bias\n",
      "mnm.memfunc.expected_activation.weight\n",
      "mnm.memfunc.expected_activation.bias\n",
      "mnm.kv_rate.weight\n",
      "mnm.kv_rate.bias\n",
      "mnm.read_out.weight\n",
      "mnm.read_out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bot(\n",
       "  (vocab): Vocab(\n",
       "    (embedding): Embedding(4, 32)\n",
       "    (emb2vocab): Linear(in_features=32, out_features=4, bias=False)\n",
       "  )\n",
       "  (encodeInput): Transformer(\n",
       "    (pe): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encodelayers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decodelayers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (encodeEncoding): Transformer(\n",
       "    (pe): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encodelayers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decodelayers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (decodeEncoding): Transformer(\n",
       "    (pe): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encodelayers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decodelayers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (mnm): MNMp(\n",
       "    (control): LSTMCell(64, 32)\n",
       "    (interaction): Linear(in_features=32, out_features=224, bias=True)\n",
       "    (memfunc): FFMemoryLearned(\n",
       "      (expected_activation): Linear(in_features=32, out_features=96, bias=True)\n",
       "    )\n",
       "    (kv_rate): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (read_out): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab.emb2vocab.weight = pickle.load(open(\"modelstate/emb2vocab.weight.p\",\"rb\"))\n",
    "model.vocab.embedding.weight = pickle.load(open(\"modelstate/embedding.weight.p\",\"rb\"))\n",
    "model.vocab.word2index = pickle.load(open(\"modelstate/word2index.p\",\"rb\"))\n",
    "model.vocab.index2word = pickle.load(open(\"modelstate/index2word.p\",\"rb\"))\n",
    "load_model(model,\"modelstate/task.pth\")\n",
    "model.mnm.memfunc.Ws = pickle.load(open(\"modelstate/Ws.p\",\"rb\"))\n",
    "model.context_vec = pickle.load(open(\"modelstate/context_vec.p\",\"rb\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > my name is melissa\n",
      " > hi melissa\n",
      " \n",
      " > what is my name?\n",
      " > its melissa\n",
      " \n",
      " > my name is vicki\n",
      " > hi vicki\n",
      " \n",
      " > what is my name?\n",
      " > its vicki\n",
      " \n",
      " > my name is zen\n",
      " > hi zen\n",
      " \n",
      " > what is my name?\n",
      " > its zen\n",
      " \n",
      " > my name is sky\n",
      " > hi sky\n",
      " \n",
      " > what is my name?\n",
      " > its sky\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for tell in [\n",
    "             'my name is melissa', 'what is my name?', \n",
    "             'my name is vicki', 'what is my name?',\n",
    "             'my name is zen', 'what is my name?',\n",
    "             'my name is sky', 'what is my name?',\n",
    "             ]:\n",
    "\n",
    "    print(' > '+ tell)\n",
    "    reply = model.string2string(tell)\n",
    "    print(' > '+ reply)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
