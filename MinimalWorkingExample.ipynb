{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version 1.7.0\n",
      "torch.cuda.is_available() True\n",
      "torch.cuda.device_count() 2\n"
     ]
    }
   ],
   "source": [
    "import math, copy, sys, logging, json, time, random, os, string, pickle, re\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.TransformerComponents import Transformer\n",
    "from modules.Vocabulary import Vocab\n",
    "from modules.MetaLearnNeuralMemory import MNMp\n",
    "from modules.LoadTrainSave import save_model, load_model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(0) \n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print('torch.version', torch.__version__)\n",
    "print('torch.cuda.is_available()', torch.cuda.is_available())\n",
    "print('torch.cuda.device_count()', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Working Example\n",
    "\n",
    "This notebook serves as a minimal working example of Meta-Learned Nerual Memory Chatbot (MNMC). The Teacher teaches a simple conversational lesson, \"when I tell you a name, remember my name, when I ask you want my name is, tell me what my name is, if I tell you I have a different name, memorize that new name, when I ask you what my name is, tell me the most recent name I told you\" \n",
    "\n",
    "# Why is this special?\n",
    "\n",
    "Seems like a somewhat mundane task, however, the mechanism by which it is accomplished is what is profound. The \"name\" is not stored in any kind of traditional database or data structure, but rather has been stored in the distributed, aka, shared, weights of a neural network. No new row or element is added to a table or array when the name is remembered, instead the values of a finite set of weights is adjusted. \n",
    "\n",
    "# Explaination\n",
    "\n",
    "Here we show an end to end, albeit minimal, example, the subsequent notebooks will explain Metalearned Nerual memory and how we have combined this with the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(): \n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        \n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.vocab.string2embedding(\"my name is, hi. what is my name? its\")\n",
    "        \n",
    "        self.name_list = [\n",
    "                          'vicki', 'carson', 'melissa', 'salvador', \n",
    "                          'force', 'sky', 'zen', 'adam'\n",
    "                         ]\n",
    "\n",
    "    def random_name(self,):\n",
    "        \"\"\" Generate a random string of fixed length \"\"\"\n",
    "        return random.choice(self.name_list)\n",
    "    \n",
    "    def repeat(self, batch_size):\n",
    "        \n",
    "        self.mynameis = self.vocab.string2tensor(\"my name is\")\n",
    "        self.hi = self.vocab.string2tensor(\"hi\")\n",
    "        self.whatmyname = self.vocab.string2tensor(\"what is my name?\")\n",
    "        self.its = self.vocab.string2tensor(\"its\")\n",
    "\n",
    "        self.mynameis = self.mynameis.repeat(batch_size,1)\n",
    "        self.hi = self.hi.repeat(batch_size,1)\n",
    "        self.whatmyname = self.whatmyname.repeat(batch_size,1)\n",
    "        self.its = self.its.repeat(batch_size,1)\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        \n",
    "        self.repeat(batch_size)\n",
    "        \n",
    "        newnames = \"\"\n",
    "        for n in range(batch_size):\n",
    "            newnames += \" \" + self.random_name()\n",
    "            \n",
    "        self.vocab.string2embedding(newnames)\n",
    "        \n",
    "        self.names = self.vocab.string2tensor(newnames).T\n",
    "\n",
    "        self.intro = torch.cat((self.mynameis, self.names),dim=1)\n",
    "        self.introtarget = torch.cat((self.hi, self.names),dim=1)\n",
    "        self.yournameis = torch.cat((self.its, self.names),dim=1)\n",
    "        \n",
    "        return self.intro, self.introtarget, self.whatmyname, self.yournameis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of the training data outputted from the teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'my': 4, 'name': 5, 'is': 6, ',': 7, 'hi': 8, '.': 9, 'what': 10, '?': 11, 'its': 12}\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(emb_dim=32)\n",
    "teacher = Teacher(vocab)\n",
    "\n",
    "print(vocab.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'my': 4, 'name': 5, 'is': 6, ',': 7, 'hi': 8, '.': 9, 'what': 10, '?': 11, 'its': 12, 'zen': 13, 'vicki': 14, 'force': 15}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "intro, introtarget, whatmyname, yournameis = teacher.get_batch(batch_size)\n",
    "\n",
    "print(vocab.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6, 13],\n",
       "        [ 4,  5,  6, 13],\n",
       "        [ 4,  5,  6, 14],\n",
       "        [ 4,  5,  6, 15]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro # my name is <new token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 13],\n",
       "        [ 8, 13],\n",
       "        [ 8, 14],\n",
       "        [ 8, 15]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introtarget # hi <new token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  6,  4,  5, 11],\n",
       "        [10,  6,  4,  5, 11],\n",
       "        [10,  6,  4,  5, 11],\n",
       "        [10,  6,  4,  5, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatmyname # what is my name ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 13],\n",
       "        [12, 13],\n",
       "        [12, 14],\n",
       "        [12, 15]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yournameis # its <new token>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Chatbot (Bot)\n",
    "\n",
    "With built in memory unit, training unit (teacher forcing) and chatting unit (string2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dim, n_layers, heads, dropout, vocab):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.sos_tok = torch.LongTensor([[self.vocab.word2index[\"<SOS>\"]]]) \n",
    "        self.eos_tok = torch.LongTensor([[self.vocab.word2index[\"<EOS>\"]]]) \n",
    "        \n",
    "        self.encodeInput = Transformer(emb_dim, n_layers, heads, dropout)\n",
    "        self.encodeEncoding = Transformer(emb_dim, n_layers, heads, dropout)\n",
    "        self.decodeEncoding = Transformer(emb_dim, n_layers, heads, dropout)\n",
    "\n",
    "        self.mnm = MNMp(emb_dim, heads)\n",
    "        \n",
    "        self.context_vec = None\n",
    "        \n",
    "    def memory_utils(self, batch_size):\n",
    "\n",
    "        if self.context_vec is None:\n",
    "            cntxt_seq_len = 1\n",
    "            self.context_vec = torch.randn(batch_size, cntxt_seq_len, self.emb_dim)\n",
    "            \n",
    "        if self.context_vec.shape[0] > batch_size:\n",
    "            self.context_vec = self.context_vec[0,:,:]\n",
    "            \n",
    "        if self.context_vec.shape[0] < batch_size:\n",
    "            self.context_vec = self.context_vec[0,:,:].repeat(batch_size, 1, 1)\n",
    "    \n",
    "        self.context_vec = self.context_vec.detach()\n",
    "        self.mnm.memfunc.detach_mem()\n",
    "        \n",
    "    def forward(self, in_toks, in_mask, out_toks, out_mask):\n",
    "        \n",
    "        self.memory_utils(batch_size = in_toks.shape[0])\n",
    "        \n",
    "        in_vecs = self.vocab.embedding(in_toks)\n",
    "        out_vec = self.vocab.embedding(out_toks)\n",
    "\n",
    "        self.context_vec, rcl, rcli = self.mnm(self.context_vec)\n",
    "        encin_vec = self.encodeInput(in_vecs, in_mask, self.context_vec, None)\n",
    "        self.context_vec = self.encodeEncoding(self.context_vec, None, encin_vec, None)\n",
    "        \n",
    "        dout = self.decodeEncoding(out_vec, out_mask, encin_vec, in_mask)\n",
    "        \n",
    "        return dout, rcl, rcli\n",
    "    \n",
    "    def teacher_forcing(self, src, trg):\n",
    "        \n",
    "        self.train()\n",
    "        trg_start = torch.cat((self.sos_tok.repeat(trg.shape[0],1), trg),dim=1)\n",
    "        trg_end = torch.cat((trg, self.eos_tok.repeat(trg.shape[0],1)),dim=1)\n",
    "        src_mask = (src != self.vocab.word2index[\"<PAD>\"]).unsqueeze(-2)\n",
    "        trg_mask = (trg_end != self.vocab.word2index[\"<PAD>\"]).unsqueeze(-2)\n",
    "        \n",
    "        seq_len = trg_start.size(1) \n",
    "        np_mask = np.triu(np.ones((1,seq_len,seq_len)),k=1).astype('uint8')\n",
    "        np_mask =  torch.from_numpy(np_mask) == 0\n",
    "        \n",
    "        if trg.is_cuda:\n",
    "            np_mask = np_mask.cuda()\n",
    "            \n",
    "        trg_mask = trg_mask & np_mask\n",
    "        \n",
    "        out_vecs, rcl, rcli = self.forward(src, src_mask, trg_start, trg_mask)\n",
    "        \n",
    "        return out_vecs, trg_end, rcl, rcli\n",
    "    \n",
    "    def string2string(self, input_string, maxlen = 20):\n",
    "        \n",
    "        self.eval()\n",
    "        in_toks = self.vocab.string2tensor(input_string)\n",
    "        in_vecs = self.vocab.embedding(in_toks)\n",
    "        \n",
    "        self.memory_utils(batch_size=in_toks.shape[0])\n",
    "        \n",
    "        self.context_vec, rcl, rcli = self.mnm(self.context_vec)\n",
    "        encin_vec = self.encodeInput(in_vecs, None, self.context_vec, None)\n",
    "        self.context_vec = self.encodeEncoding(self.context_vec, None, encin_vec, None)\n",
    "        \n",
    "        decode_toks = self.sos_tok\n",
    "        \n",
    "        for pos in range(maxlen):\n",
    "            \n",
    "            decode_vecs = self.vocab.embedding(decode_toks)\n",
    "            dout = self.decodeEncoding(decode_vecs, None, encin_vec, None)\n",
    "            vocabdist = self.vocab.emb2vocab(dout)\n",
    "            next_toks = torch.argmax(vocabdist, dim=2)\n",
    "            decode_toks = torch.cat((decode_toks, next_toks[:,-1].unsqueeze(0)), dim=1) \n",
    "            \n",
    "            if next_toks[:,-1] == self.eos_tok.squeeze(0):\n",
    "                \n",
    "                toks = decode_toks[0][1:-1].data.cpu().numpy()\n",
    "                de_str = ' '.join([self.vocab.index2word[int(tok)] for tok in toks])\n",
    "\n",
    "                return de_str\n",
    "            \n",
    "        toks = decode_toks[0].data.cpu().numpy()\n",
    "        de_str = ' '.join([self.vocab.index2word[tok] for tok in toks])\n",
    "        return de_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the vocab, model and teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'my': 4, 'name': 5, 'is': 6, ',': 7, 'hi': 8, '.': 9, 'what': 10, '?': 11, 'its': 12}\n"
     ]
    }
   ],
   "source": [
    "emb_dim, n_layers, heads, dropout = 32, 2, 2, 0.05\n",
    "\n",
    "vocab = Vocab(emb_dim)\n",
    "model = Bot(emb_dim, n_layers, heads, dropout, vocab)\n",
    "teacher = Teacher(model.vocab)\n",
    "\n",
    "print(model.vocab.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model...\n",
      "mean accuracy 0.0521 celoss 23.0069 rcloss 0.987012 d_rcloss 0.0382 training progress 0.0 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.3203 celoss 2.4261 rcloss 0.000799 d_rcloss 0.0258 training progress 0.0516 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.3715 celoss 2.2292 rcloss 0.00011 d_rcloss 0.0285 training progress 0.1031 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.4583 celoss 1.6953 rcloss 0.001774 d_rcloss 0.0241 training progress 0.1547 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.5177 celoss 1.3539 rcloss 0.000222 d_rcloss 0.0227 training progress 0.2062 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.5495 celoss 0.9253 rcloss 0.00019 d_rcloss 0.0227 training progress 0.2578 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.5722 celoss 0.8567 rcloss 0.000195 d_rcloss 0.0283 training progress 0.3094 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.5931 celoss 0.7619 rcloss 0.004519 d_rcloss 0.0291 training progress 0.3609 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.6157 celoss 0.5526 rcloss 0.002589 d_rcloss 0.0323 training progress 0.4125 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.6344 celoss 0.4589 rcloss 0.003951 d_rcloss 0.0369 training progress 0.4641 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.7047 celoss 0.6 rcloss 0.001811 d_rcloss 0.0307 training progress 0.5156 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.7307 celoss 0.3867 rcloss 0.001297 d_rcloss 0.0378 training progress 0.5672 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.7719 celoss 0.4072 rcloss 0.003857 d_rcloss 0.0423 training progress 0.6188 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.7927 celoss 0.2159 rcloss 0.002377 d_rcloss 0.0381 training progress 0.6703 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8062 celoss 0.2612 rcloss 0.003566 d_rcloss 0.0528 training progress 0.7219 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8323 celoss 0.114 rcloss 0.002158 d_rcloss 0.0404 training progress 0.7734 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8562 celoss 0.1678 rcloss 0.002122 d_rcloss 0.0336 training progress 0.825 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8776 celoss 0.1997 rcloss 0.001006 d_rcloss 0.0334 training progress 0.8766 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.8953 celoss 0.0903 rcloss 0.000882 d_rcloss 0.0406 training progress 0.9281 learning rate [0.01]\n",
      "Saving Model...\n",
      "mean accuracy 0.9135 celoss 0.0731 rcloss 0.000919 d_rcloss 0.038 training progress 0.9797 learning rate [0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f142478f4a8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_batches = 64*10\n",
    "best_acc = 0\n",
    "lamda = 8\n",
    "batch_size = 64\n",
    "learning_rate = 0.01 #0.001\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate,betas=(0.9, 0.98),eps=1e-9)\n",
    "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',factor=0.99,patience=100)\n",
    "\n",
    "loss_all_list = []\n",
    "rcloss_all_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for batch in range(total_batches):\n",
    "    \n",
    "    intro, introtarget, whatmyname, yournameis = teacher.get_batch(batch_size)\n",
    "    \n",
    "    out_vecs, trg_end, rcl, rcli = model.teacher_forcing(intro, introtarget)\n",
    "    \n",
    "    vocab_logits = model.vocab.emb2vocab(out_vecs)\n",
    "    \n",
    "    predictions = vocab_logits.view(-1, vocab_logits.size(-1))\n",
    "    \n",
    "    target = trg_end.view(-1)\n",
    "\n",
    "    batch_loss = F.cross_entropy(predictions, target, \n",
    "                                 ignore_index = model.vocab.word2index[\"<PAD>\"])\n",
    "\n",
    "    reconstruction_loss = lamda*rcl\n",
    "    \n",
    "    ################# Next Part of Conversation ########################\n",
    "    \n",
    "    out_vecs, trg_end, rcl, rcli = model.teacher_forcing(whatmyname, yournameis)\n",
    "    \n",
    "    vocab_logits = model.vocab.emb2vocab(out_vecs)\n",
    "\n",
    "    predictions = vocab_logits.view(-1, vocab_logits.size(-1))\n",
    "    \n",
    "    target = trg_end.view(-1)\n",
    "    \n",
    "    acc = accuracy_score(target, torch.argmax(predictions, dim=1))\n",
    "\n",
    "    batch_loss += F.cross_entropy(predictions, target, \n",
    "                                 ignore_index = model.vocab.word2index[\"<PAD>\"])\n",
    "    \n",
    "    reconstruction_loss += lamda*rcl\n",
    "    conversation_loss = batch_loss + reconstruction_loss\n",
    "    \n",
    "    scheduler.step(conversation_loss)\n",
    "    optimizer.zero_grad()\n",
    "    conversation_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch % int(total_batches/20 + 1) == 0:\n",
    "        \n",
    "        loss_all_list.append(conversation_loss.float().item())\n",
    "        rcloss_all_list.append(reconstruction_loss.float().item())\n",
    "        accuracy_list.append(acc)\n",
    "        mean_accuracy = np.mean(accuracy_list[-10:])\n",
    "\n",
    "        if mean_accuracy > best_acc:\n",
    "            print('Saving Model...')\n",
    "            best_acc = mean_accuracy\n",
    "            \n",
    "            pickle.dump(model.vocab.word2index,open(\"modelstate/word2index.p\",\"wb\"))\n",
    "            pickle.dump(model.vocab.index2word,open(\"modelstate/index2word.p\",\"wb\"))\n",
    "            pickle.dump(model.vocab.emb2vocab.weight,open(\"modelstate/emb2vocab.weight.p\",\"wb\"))\n",
    "            pickle.dump(model.vocab.embedding.weight,open(\"modelstate/embedding.weight.p\",\"wb\"))\n",
    "            pickle.dump(model.context_vec,open(\"modelstate/context_vec.p\",\"wb\"))\n",
    "            pickle.dump(model.mnm.memfunc.Ws,open(\"modelstate/Ws.p\",\"wb\"))\n",
    "            save_model(model,\"modelstate/task.pth\")\n",
    "            \n",
    "        print(\"mean accuracy\", round(mean_accuracy,4), \n",
    "              \"celoss\", round(batch_loss.float().item(),4), \n",
    "              \"rcloss\", round(reconstruction_loss.float().item(),6), \n",
    "              \"d_rcloss\", round((rcli - rcl).float().item(),4),\n",
    "              \"training progress\", round(batch/total_batches,4),\n",
    "              \"learning rate\", scheduler._last_lr)\n",
    "            \n",
    "        if mean_accuracy > 0.97:\n",
    "            break\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "fig.suptitle('Training Curves')\n",
    "ax1.set(xlabel='epochs', ylabel='train loss')\n",
    "ax2.set(xlabel='epochs', ylabel='reconstr loss')\n",
    "ax3.set(xlabel='epochs', ylabel='accuracy')\n",
    "ax1.plot(loss_all_list, label='train loss')\n",
    "ax2.plot(rcloss_all_list, label='reconstrunction loss')\n",
    "ax3.plot(accuracy_list, label='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the names of all the trainable parameters, aka, weights in this model. there are a few other parameters that are not in the computational graph of pytorch, which is why there are other saved files to be saved and re-loaded besides `save_model(model,\"modelstate/task.pth\")` such as the embeddings, vocabulary dictionary, the vector that stores the last memory and the matrices that store the memories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab.embedding.weight\n",
      "vocab.emb2vocab.weight\n",
      "encodeInput.encodelayers.0.norm_1.alpha\n",
      "encodeInput.encodelayers.0.norm_1.bias\n",
      "encodeInput.encodelayers.0.attn.q_linear.weight\n",
      "encodeInput.encodelayers.0.attn.q_linear.bias\n",
      "encodeInput.encodelayers.0.attn.k_linear.weight\n",
      "encodeInput.encodelayers.0.attn.k_linear.bias\n",
      "encodeInput.encodelayers.0.attn.v_linear.weight\n",
      "encodeInput.encodelayers.0.attn.v_linear.bias\n",
      "encodeInput.encodelayers.0.attn.out.weight\n",
      "encodeInput.encodelayers.0.attn.out.bias\n",
      "encodeInput.encodelayers.0.norm_2.alpha\n",
      "encodeInput.encodelayers.0.norm_2.bias\n",
      "encodeInput.encodelayers.0.ff.linear_1.weight\n",
      "encodeInput.encodelayers.0.ff.linear_1.bias\n",
      "encodeInput.encodelayers.0.ff.linear_2.weight\n",
      "encodeInput.encodelayers.0.ff.linear_2.bias\n",
      "encodeInput.encodelayers.1.norm_1.alpha\n",
      "encodeInput.encodelayers.1.norm_1.bias\n",
      "encodeInput.encodelayers.1.attn.q_linear.weight\n",
      "encodeInput.encodelayers.1.attn.q_linear.bias\n",
      "encodeInput.encodelayers.1.attn.k_linear.weight\n",
      "encodeInput.encodelayers.1.attn.k_linear.bias\n",
      "encodeInput.encodelayers.1.attn.v_linear.weight\n",
      "encodeInput.encodelayers.1.attn.v_linear.bias\n",
      "encodeInput.encodelayers.1.attn.out.weight\n",
      "encodeInput.encodelayers.1.attn.out.bias\n",
      "encodeInput.encodelayers.1.norm_2.alpha\n",
      "encodeInput.encodelayers.1.norm_2.bias\n",
      "encodeInput.encodelayers.1.ff.linear_1.weight\n",
      "encodeInput.encodelayers.1.ff.linear_1.bias\n",
      "encodeInput.encodelayers.1.ff.linear_2.weight\n",
      "encodeInput.encodelayers.1.ff.linear_2.bias\n",
      "encodeInput.decodelayers.0.norm_1.alpha\n",
      "encodeInput.decodelayers.0.norm_1.bias\n",
      "encodeInput.decodelayers.0.norm_2.alpha\n",
      "encodeInput.decodelayers.0.norm_2.bias\n",
      "encodeInput.decodelayers.0.norm_3.alpha\n",
      "encodeInput.decodelayers.0.norm_3.bias\n",
      "encodeInput.decodelayers.0.attn_1.q_linear.weight\n",
      "encodeInput.decodelayers.0.attn_1.q_linear.bias\n",
      "encodeInput.decodelayers.0.attn_1.k_linear.weight\n",
      "encodeInput.decodelayers.0.attn_1.k_linear.bias\n",
      "encodeInput.decodelayers.0.attn_1.v_linear.weight\n",
      "encodeInput.decodelayers.0.attn_1.v_linear.bias\n",
      "encodeInput.decodelayers.0.attn_1.out.weight\n",
      "encodeInput.decodelayers.0.attn_1.out.bias\n",
      "encodeInput.decodelayers.0.attn_2.q_linear.weight\n",
      "encodeInput.decodelayers.0.attn_2.q_linear.bias\n",
      "encodeInput.decodelayers.0.attn_2.k_linear.weight\n",
      "encodeInput.decodelayers.0.attn_2.k_linear.bias\n",
      "encodeInput.decodelayers.0.attn_2.v_linear.weight\n",
      "encodeInput.decodelayers.0.attn_2.v_linear.bias\n",
      "encodeInput.decodelayers.0.attn_2.out.weight\n",
      "encodeInput.decodelayers.0.attn_2.out.bias\n",
      "encodeInput.decodelayers.0.ff.linear_1.weight\n",
      "encodeInput.decodelayers.0.ff.linear_1.bias\n",
      "encodeInput.decodelayers.0.ff.linear_2.weight\n",
      "encodeInput.decodelayers.0.ff.linear_2.bias\n",
      "encodeInput.decodelayers.1.norm_1.alpha\n",
      "encodeInput.decodelayers.1.norm_1.bias\n",
      "encodeInput.decodelayers.1.norm_2.alpha\n",
      "encodeInput.decodelayers.1.norm_2.bias\n",
      "encodeInput.decodelayers.1.norm_3.alpha\n",
      "encodeInput.decodelayers.1.norm_3.bias\n",
      "encodeInput.decodelayers.1.attn_1.q_linear.weight\n",
      "encodeInput.decodelayers.1.attn_1.q_linear.bias\n",
      "encodeInput.decodelayers.1.attn_1.k_linear.weight\n",
      "encodeInput.decodelayers.1.attn_1.k_linear.bias\n",
      "encodeInput.decodelayers.1.attn_1.v_linear.weight\n",
      "encodeInput.decodelayers.1.attn_1.v_linear.bias\n",
      "encodeInput.decodelayers.1.attn_1.out.weight\n",
      "encodeInput.decodelayers.1.attn_1.out.bias\n",
      "encodeInput.decodelayers.1.attn_2.q_linear.weight\n",
      "encodeInput.decodelayers.1.attn_2.q_linear.bias\n",
      "encodeInput.decodelayers.1.attn_2.k_linear.weight\n",
      "encodeInput.decodelayers.1.attn_2.k_linear.bias\n",
      "encodeInput.decodelayers.1.attn_2.v_linear.weight\n",
      "encodeInput.decodelayers.1.attn_2.v_linear.bias\n",
      "encodeInput.decodelayers.1.attn_2.out.weight\n",
      "encodeInput.decodelayers.1.attn_2.out.bias\n",
      "encodeInput.decodelayers.1.ff.linear_1.weight\n",
      "encodeInput.decodelayers.1.ff.linear_1.bias\n",
      "encodeInput.decodelayers.1.ff.linear_2.weight\n",
      "encodeInput.decodelayers.1.ff.linear_2.bias\n",
      "encodeInput.norm.alpha\n",
      "encodeInput.norm.bias\n",
      "encodeEncoding.encodelayers.0.norm_1.alpha\n",
      "encodeEncoding.encodelayers.0.norm_1.bias\n",
      "encodeEncoding.encodelayers.0.attn.q_linear.weight\n",
      "encodeEncoding.encodelayers.0.attn.q_linear.bias\n",
      "encodeEncoding.encodelayers.0.attn.k_linear.weight\n",
      "encodeEncoding.encodelayers.0.attn.k_linear.bias\n",
      "encodeEncoding.encodelayers.0.attn.v_linear.weight\n",
      "encodeEncoding.encodelayers.0.attn.v_linear.bias\n",
      "encodeEncoding.encodelayers.0.attn.out.weight\n",
      "encodeEncoding.encodelayers.0.attn.out.bias\n",
      "encodeEncoding.encodelayers.0.norm_2.alpha\n",
      "encodeEncoding.encodelayers.0.norm_2.bias\n",
      "encodeEncoding.encodelayers.0.ff.linear_1.weight\n",
      "encodeEncoding.encodelayers.0.ff.linear_1.bias\n",
      "encodeEncoding.encodelayers.0.ff.linear_2.weight\n",
      "encodeEncoding.encodelayers.0.ff.linear_2.bias\n",
      "encodeEncoding.encodelayers.1.norm_1.alpha\n",
      "encodeEncoding.encodelayers.1.norm_1.bias\n",
      "encodeEncoding.encodelayers.1.attn.q_linear.weight\n",
      "encodeEncoding.encodelayers.1.attn.q_linear.bias\n",
      "encodeEncoding.encodelayers.1.attn.k_linear.weight\n",
      "encodeEncoding.encodelayers.1.attn.k_linear.bias\n",
      "encodeEncoding.encodelayers.1.attn.v_linear.weight\n",
      "encodeEncoding.encodelayers.1.attn.v_linear.bias\n",
      "encodeEncoding.encodelayers.1.attn.out.weight\n",
      "encodeEncoding.encodelayers.1.attn.out.bias\n",
      "encodeEncoding.encodelayers.1.norm_2.alpha\n",
      "encodeEncoding.encodelayers.1.norm_2.bias\n",
      "encodeEncoding.encodelayers.1.ff.linear_1.weight\n",
      "encodeEncoding.encodelayers.1.ff.linear_1.bias\n",
      "encodeEncoding.encodelayers.1.ff.linear_2.weight\n",
      "encodeEncoding.encodelayers.1.ff.linear_2.bias\n",
      "encodeEncoding.decodelayers.0.norm_1.alpha\n",
      "encodeEncoding.decodelayers.0.norm_1.bias\n",
      "encodeEncoding.decodelayers.0.norm_2.alpha\n",
      "encodeEncoding.decodelayers.0.norm_2.bias\n",
      "encodeEncoding.decodelayers.0.norm_3.alpha\n",
      "encodeEncoding.decodelayers.0.norm_3.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.q_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.q_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.k_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.k_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.v_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.v_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_1.out.weight\n",
      "encodeEncoding.decodelayers.0.attn_1.out.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.q_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.q_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.k_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.k_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.v_linear.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.v_linear.bias\n",
      "encodeEncoding.decodelayers.0.attn_2.out.weight\n",
      "encodeEncoding.decodelayers.0.attn_2.out.bias\n",
      "encodeEncoding.decodelayers.0.ff.linear_1.weight\n",
      "encodeEncoding.decodelayers.0.ff.linear_1.bias\n",
      "encodeEncoding.decodelayers.0.ff.linear_2.weight\n",
      "encodeEncoding.decodelayers.0.ff.linear_2.bias\n",
      "encodeEncoding.decodelayers.1.norm_1.alpha\n",
      "encodeEncoding.decodelayers.1.norm_1.bias\n",
      "encodeEncoding.decodelayers.1.norm_2.alpha\n",
      "encodeEncoding.decodelayers.1.norm_2.bias\n",
      "encodeEncoding.decodelayers.1.norm_3.alpha\n",
      "encodeEncoding.decodelayers.1.norm_3.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.q_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.q_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.k_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.k_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.v_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.v_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_1.out.weight\n",
      "encodeEncoding.decodelayers.1.attn_1.out.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.q_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.q_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.k_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.k_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.v_linear.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.v_linear.bias\n",
      "encodeEncoding.decodelayers.1.attn_2.out.weight\n",
      "encodeEncoding.decodelayers.1.attn_2.out.bias\n",
      "encodeEncoding.decodelayers.1.ff.linear_1.weight\n",
      "encodeEncoding.decodelayers.1.ff.linear_1.bias\n",
      "encodeEncoding.decodelayers.1.ff.linear_2.weight\n",
      "encodeEncoding.decodelayers.1.ff.linear_2.bias\n",
      "encodeEncoding.norm.alpha\n",
      "encodeEncoding.norm.bias\n",
      "decodeEncoding.encodelayers.0.norm_1.alpha\n",
      "decodeEncoding.encodelayers.0.norm_1.bias\n",
      "decodeEncoding.encodelayers.0.attn.q_linear.weight\n",
      "decodeEncoding.encodelayers.0.attn.q_linear.bias\n",
      "decodeEncoding.encodelayers.0.attn.k_linear.weight\n",
      "decodeEncoding.encodelayers.0.attn.k_linear.bias\n",
      "decodeEncoding.encodelayers.0.attn.v_linear.weight\n",
      "decodeEncoding.encodelayers.0.attn.v_linear.bias\n",
      "decodeEncoding.encodelayers.0.attn.out.weight\n",
      "decodeEncoding.encodelayers.0.attn.out.bias\n",
      "decodeEncoding.encodelayers.0.norm_2.alpha\n",
      "decodeEncoding.encodelayers.0.norm_2.bias\n",
      "decodeEncoding.encodelayers.0.ff.linear_1.weight\n",
      "decodeEncoding.encodelayers.0.ff.linear_1.bias\n",
      "decodeEncoding.encodelayers.0.ff.linear_2.weight\n",
      "decodeEncoding.encodelayers.0.ff.linear_2.bias\n",
      "decodeEncoding.encodelayers.1.norm_1.alpha\n",
      "decodeEncoding.encodelayers.1.norm_1.bias\n",
      "decodeEncoding.encodelayers.1.attn.q_linear.weight\n",
      "decodeEncoding.encodelayers.1.attn.q_linear.bias\n",
      "decodeEncoding.encodelayers.1.attn.k_linear.weight\n",
      "decodeEncoding.encodelayers.1.attn.k_linear.bias\n",
      "decodeEncoding.encodelayers.1.attn.v_linear.weight\n",
      "decodeEncoding.encodelayers.1.attn.v_linear.bias\n",
      "decodeEncoding.encodelayers.1.attn.out.weight\n",
      "decodeEncoding.encodelayers.1.attn.out.bias\n",
      "decodeEncoding.encodelayers.1.norm_2.alpha\n",
      "decodeEncoding.encodelayers.1.norm_2.bias\n",
      "decodeEncoding.encodelayers.1.ff.linear_1.weight\n",
      "decodeEncoding.encodelayers.1.ff.linear_1.bias\n",
      "decodeEncoding.encodelayers.1.ff.linear_2.weight\n",
      "decodeEncoding.encodelayers.1.ff.linear_2.bias\n",
      "decodeEncoding.decodelayers.0.norm_1.alpha\n",
      "decodeEncoding.decodelayers.0.norm_1.bias\n",
      "decodeEncoding.decodelayers.0.norm_2.alpha\n",
      "decodeEncoding.decodelayers.0.norm_2.bias\n",
      "decodeEncoding.decodelayers.0.norm_3.alpha\n",
      "decodeEncoding.decodelayers.0.norm_3.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.q_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.q_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.k_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.k_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.v_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.v_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_1.out.weight\n",
      "decodeEncoding.decodelayers.0.attn_1.out.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.q_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.q_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.k_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.k_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.v_linear.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.v_linear.bias\n",
      "decodeEncoding.decodelayers.0.attn_2.out.weight\n",
      "decodeEncoding.decodelayers.0.attn_2.out.bias\n",
      "decodeEncoding.decodelayers.0.ff.linear_1.weight\n",
      "decodeEncoding.decodelayers.0.ff.linear_1.bias\n",
      "decodeEncoding.decodelayers.0.ff.linear_2.weight\n",
      "decodeEncoding.decodelayers.0.ff.linear_2.bias\n",
      "decodeEncoding.decodelayers.1.norm_1.alpha\n",
      "decodeEncoding.decodelayers.1.norm_1.bias\n",
      "decodeEncoding.decodelayers.1.norm_2.alpha\n",
      "decodeEncoding.decodelayers.1.norm_2.bias\n",
      "decodeEncoding.decodelayers.1.norm_3.alpha\n",
      "decodeEncoding.decodelayers.1.norm_3.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.q_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.q_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.k_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.k_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.v_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.v_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_1.out.weight\n",
      "decodeEncoding.decodelayers.1.attn_1.out.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.q_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.q_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.k_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.k_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.v_linear.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.v_linear.bias\n",
      "decodeEncoding.decodelayers.1.attn_2.out.weight\n",
      "decodeEncoding.decodelayers.1.attn_2.out.bias\n",
      "decodeEncoding.decodelayers.1.ff.linear_1.weight\n",
      "decodeEncoding.decodelayers.1.ff.linear_1.bias\n",
      "decodeEncoding.decodelayers.1.ff.linear_2.weight\n",
      "decodeEncoding.decodelayers.1.ff.linear_2.bias\n",
      "decodeEncoding.norm.alpha\n",
      "decodeEncoding.norm.bias\n",
      "mnm.control.weight_ih\n",
      "mnm.control.weight_hh\n",
      "mnm.control.bias_ih\n",
      "mnm.control.bias_hh\n",
      "mnm.interaction.weight\n",
      "mnm.interaction.bias\n",
      "mnm.memfunc.expected_activation.weight\n",
      "mnm.memfunc.expected_activation.bias\n",
      "mnm.kv_rate.weight\n",
      "mnm.kv_rate.bias\n",
      "mnm.read_out.weight\n",
      "mnm.read_out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bot(\n",
       "  (vocab): Vocab(\n",
       "    (embedding): Embedding(4, 32)\n",
       "    (emb2vocab): Linear(in_features=32, out_features=4, bias=False)\n",
       "  )\n",
       "  (encodeInput): Transformer(\n",
       "    (pe): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encodelayers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decodelayers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (encodeEncoding): Transformer(\n",
       "    (pe): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encodelayers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decodelayers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (decodeEncoding): Transformer(\n",
       "    (pe): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encodelayers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (norm_2): Norm()\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (decodelayers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.05, inplace=False)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (k_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (v_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (out): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (mnm): MNMp(\n",
       "    (control): LSTMCell(64, 32)\n",
       "    (interaction): Linear(in_features=32, out_features=224, bias=True)\n",
       "    (memfunc): FFMemoryLearned(\n",
       "      (expected_activation): Linear(in_features=32, out_features=96, bias=True)\n",
       "    )\n",
       "    (kv_rate): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (read_out): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab.emb2vocab.weight = pickle.load(open(\"modelstate/emb2vocab.weight.p\",\"rb\"))\n",
    "model.vocab.embedding.weight = pickle.load(open(\"modelstate/embedding.weight.p\",\"rb\"))\n",
    "model.vocab.word2index = pickle.load(open(\"modelstate/word2index.p\",\"rb\"))\n",
    "model.vocab.index2word = pickle.load(open(\"modelstate/index2word.p\",\"rb\"))\n",
    "load_model(model,\"modelstate/task.pth\")\n",
    "model.mnm.memfunc.Ws = pickle.load(open(\"modelstate/Ws.p\",\"rb\"))\n",
    "model.context_vec = pickle.load(open(\"modelstate/context_vec.p\",\"rb\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > my name is melissa\n",
      " > hi melissa\n",
      " \n",
      " > what is my name?\n",
      " > its melissa\n",
      " \n",
      " > my name is vicki\n",
      " > hi vicki\n",
      " \n",
      " > what is my name?\n",
      " > its vicki\n",
      " \n",
      " > my name is zen\n",
      " > hi zen\n",
      " \n",
      " > what is my name?\n",
      " > its zen\n",
      " \n",
      " > my name is sky\n",
      " > hi sky\n",
      " \n",
      " > what is my name?\n",
      " > its sky\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for tell in [\n",
    "             'my name is melissa', 'what is my name?', \n",
    "             'my name is vicki', 'what is my name?',\n",
    "             'my name is zen', 'what is my name?',\n",
    "             'my name is sky', 'what is my name?',\n",
    "             ]:\n",
    "\n",
    "    print(' > '+ tell)\n",
    "    reply = model.string2string(tell)\n",
    "    print(' > '+ reply)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
