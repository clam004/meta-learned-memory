{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version 1.4.0\n",
      "torch.cuda.is_available() True\n"
     ]
    }
   ],
   "source": [
    "import math, copy, sys, logging, json, time, random, os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MNM import DictInf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(0) \n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print('torch.version', torch.__version__)\n",
    "print('torch.cuda.is_available()', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a tutorial on the paper Metalearned Neural Memory\n",
    "\n",
    "[arxiv](https://arxiv.org/pdf/1907.09720.pdf) by Tsendsuren Munkhdalai\n",
    "\n",
    "We dissect the Metalearned Neural Memory Module with Local Memory Updates (MNMp) as it solves the Dictionary Inference Task\n",
    "\n",
    "## Understanding the Dictionary Inference Task\n",
    "Take the output for example:\n",
    "\n",
    "`x = [[4 3 6 1 2 7 3 3 6 2 2 7 3 3 6 2 2 7 8 4 3 6 9 9]]`\n",
    "\n",
    "`y = [[1 2]]`\n",
    "\n",
    "Here the batch size is 1, the num_items = 3, item_length =2, the n_alphabet = 4\n",
    "\n",
    "num_items translates to support set size in the paper and item_length translates to sequence length\n",
    "\n",
    "The pair separator is 6, 6 is n_alphabet + 1 + 1, since n_alphabet = 4 the pair separator = (4+1+1) = 6. Within the first 5 elements of the vector x, it separates 4, 3 from 1, 2, meaning that 4 maps to 1 and 3 maps to 2.\n",
    "\n",
    "This is the new mapping task that the networks needs to learn \"on the fly\" in order to make correct predictions\n",
    "\n",
    "The instance separator is 7, n_alphabet + 3, of which there are 3 because num_items = 3.\n",
    "\n",
    "The instance separator serves as the delimiter between these mapping pair examples. In this example here are the 3 pairs of the form `[_ _ 6 _ _ 7]`: \n",
    "\n",
    "`4 3 6 1 2 7` , `3 3 6 2 2 7`, `3 3 6 2 2 7`.\n",
    "\n",
    "8 is the prediction separator, it occurs once after the teaching is finished. It says \" now that we have shown you some examples of mappings from one integer to the other, what does `4 3 ` map to ? \n",
    "\n",
    "`6` is the last usage of the pair separator and `9 9` is essentially item_length occurances of the the pad aka placeholder. This pattern of, pair separator + placeholder x item_length denotes the end of the teaching + question session.\n",
    "\n",
    "since 4 maps to 1 and 3 maps to 2, the sequence 4, 3 maps to 1, 2 which is why the target y = 1, 2\n",
    "\n",
    "The regular case has n_alphabet = 26 so that the mappings are for terms that could be from 1 to 26, the pair separator is 28, the instance separator is 29, the prediction separator is 30 and the end of teaching + question session placeholder is 31. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 28  5 29 18 28  7 29  3 28 26 29 18 28  7 29 30 18 28 31]]\n",
      "--------------------\n",
      "[[7]]\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "config = Config()\n",
    "config.n_heads = 4\n",
    "config.batch_size =  1\n",
    "config.checkpoint = 2\n",
    "config.max_iters = 10\n",
    "\n",
    "test_generator = DictInf(batch_size=config.batch_size, max_iter=10,  \n",
    "                          min_num_items=4, max_num_items=4, \n",
    "                          min_item_length=1, max_item_length=1, \n",
    "                          checkpoint=config.checkpoint)\n",
    "\n",
    "x, y = test_generator.next() #(batch_size,),(batch_size,item_length)\n",
    "\n",
    "print(x)\n",
    "print(\"--------------------\")\n",
    "print(y)\n",
    "\n",
    "def save_model(model,name):\n",
    "    torch.save(model.state_dict(),name)\n",
    "    \n",
    "def load_model(model,name):\n",
    "    model.load_state_dict(torch.load(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## FFMemory (Feed Forward Memory)\n",
    "\n",
    "k_w, v_w are passed to the memory function along with the rate scalar beta\n",
    "\n",
    "their shapes are (batchsize, n_heads, dim_hidden) and (batch_size, 1)\n",
    "\n",
    "This is the memory unit and it comes in two forms, the local update which is gradient free, and the gradient based.\n",
    "\n",
    "Here in the FFMemoryLearned function we used the perceptron learning rule to update the memory. This is explained well here: http://hagan.okstate.edu/4_Perceptron.pdf \n",
    "\n",
    "## Perceptron Learning Rule\n",
    "\n",
    "The perceptron learning rule allows you to change the weights of a linear transformation matrix in such a way as to nudge it's output closer to or away from a desired target. It does this at the level of a single perceptron.\n",
    "\n",
    "Consider the some layer of a feed forward neural network, activations \"a\" = relu(Wx+b).\n",
    "\n",
    "\"a\" might have several dimensions, but the first dimension of \"a\" is only dependant on x and the first row of W. So if you consider W to be a single row and \"a\" to be a single activation, then without loss of generality, what applies for this row applies to the entire matrix W and the entire vector a. \n",
    "\n",
    "if W = `[-1, 1]` and b = `[-1]`, you can see by plotting W`[x_1, x_2]` + b = 0 on a x_1 by x_2 axis that this is a line with slope 1 that intersects the x_1 axis at -1. This is the decision boundary because at this boundary Wx+b=0 and on either side of the boundary you are either positive or negative.  The point p1 = x_1, x_2 = 2, 1 would be evaluated as -1 if you plugged it into Wx+b and so would be negative after the activation function. \n",
    "\n",
    "Supposed without calculating the gradient you want to change W such that the point p1 = x_1, x_2 = 2, 1 will be classified as positive. Notice that the vector for W `[-1, 1]` points down and to the right, away from p1. That direction that vector W points in, is the direction towards the side of the decision boundary that is positive in Wx. The opposite side of the boundary is negative in Wx. if you add p1 to W you get W = `[1, 2]`, and if you add the error, target - activation = 1 - 0 = 1 to the bias, you get b = 0. \n",
    "\n",
    "The new line points up and to the right and will now classify p1 correctly. Wx + b = 2+2+1 = 5. Notice that b also changes in the correct direction, if you didnt change b, the resulting decision boundary `[1, 2]`x - 1 = 0 would have been a negatively sloped line that intersects the x_1 axis at x_1 = 1, whereas now that b = 1, the intersect is at 0. This update has not only rotated the vector W to point towards p1 but shifted the decision boundary downwards pulling the boundary away from p1 so taht p1 is farther within the region of positivity and therefore more positive.\n",
    "\n",
    "$$ W_t := W_{t-1} + (target - activation) \\otimes input^{T} $$\n",
    "\n",
    "$$ b_t = b_{t-1} + (target - activation) $$\n",
    "\n",
    "The circle with an X inside is the outer product, this fits with the shape of W since if the activation is m-dimensional, and input is n-dimensional, the W is shape mxn and the bias is shape mx1. Therefore the the update to W must be the same shape as W which is the shape you would get if you performed an outer product between (target - activation) x (input^T) = (update) which has shape (mx1)(1xn) = (mxn)\n",
    "\n",
    "In this paper the target vector is not some kind of supervised label, instead it is a target that the feed forward neural memory learns to come up with in order to update all the layers of the neural network in such a way as to  bind the key value pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMemoryLearned(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_hidden):\n",
    "        \n",
    "        super(FFMemoryLearned, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(dim_hidden, dim_hidden).weight.data\n",
    "        self.l2 = nn.Linear(dim_hidden, dim_hidden).weight.data\n",
    "        self.l3 = nn.Linear(dim_hidden, dim_hidden).weight.data\n",
    "        \n",
    "        self.Ws = [self.l1, self.l2, self.l3]\n",
    "        self.Ws_temp = None\n",
    "        \n",
    "        self.expected_activation = nn.Linear(dim_hidden, 3*dim_hidden)\n",
    "\n",
    "    def if_cuda(self):\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            self.l1 = self.l1.cuda()\n",
    "            self.l2 = self.l2.cuda()\n",
    "            self.l3 = self.l3.cuda()\n",
    "        self.Ws = [self.l1, self.l2, self.l3]\n",
    "\n",
    "    def detach_mem(self):\n",
    "        for W_l in self.Ws:\n",
    "          W_l.detach()\n",
    "        self.Ws_temp = None\n",
    "\n",
    "    def forward(self, key):\n",
    "        self.if_cuda()\n",
    "        \n",
    "        if self.Ws_temp is None: # is reset at beginning of every new sequence \n",
    "          self.Ws_temp = []\n",
    "          for W_l in self.Ws:\n",
    "            W = W_l.unsqueeze(dim=0).expand((key.shape[0], W_l.shape[0], W_l.shape[1]))\n",
    "            self.Ws_temp.append(W)\n",
    "            \n",
    "        activations = [] # hidden activations \n",
    "        a = key\n",
    "        \n",
    "        for W_l in self.Ws_temp[:-1]:\n",
    "          a = torch.matmul(a, W_l.transpose(1,2))\n",
    "          a = torch.sigmoid(a)\n",
    "          activations.append(a)\n",
    "        \n",
    "        value = torch.matmul(a, self.Ws_temp[-1].transpose(1,2))\n",
    "\n",
    "        return value, activations\n",
    "\n",
    "    def mse_loss(self, y_pred, y):\n",
    "        diff = y_pred - y\n",
    "        diff = diff.view(-1)\n",
    "        mse = diff.dot(diff)/diff.size()[0]\n",
    "        return mse\n",
    "\n",
    "    def read(self, k, weights=None, avg=True):\n",
    "\n",
    "        v, h_acts = self.forward(k)\n",
    "\n",
    "        if weights is not None:\n",
    "          v *= weights\n",
    "        if avg:\n",
    "          v = v.mean(dim=1)\n",
    "        return v\n",
    "\n",
    "    def update(self, k_w, v_w, beta_rate=0.1):  \n",
    "\n",
    "        v_w_approx, activations = self.forward(k_w)\n",
    "        \n",
    "        v_w_approx = v_w_approx.contiguous()\n",
    "        v_w = v_w.contiguous()\n",
    "        \n",
    "        reconst_loss_init = self.mse_loss(v_w_approx.view(-1, v_w_approx.shape[2]), \n",
    "                                           v_w.view(-1, v_w.shape[2]))\n",
    "        \n",
    "        z_pr = self.expected_activation(v_w.view(-1, v_w.shape[2]))\n",
    "        z_pr = z_pr.view(v_w.shape[0], v_w.shape[1], -1)\n",
    "        z_pr = torch.chunk(z_pr, 3, dim=2)\n",
    "        \n",
    "        if len(beta_rate.shape) < 3:\n",
    "            beta_rate = beta_rate.unsqueeze(1)\n",
    "\n",
    "        z2 = activations + [v_w_approx]\n",
    "        z1 = [k_w] + activations\n",
    "        Ws_t = []\n",
    "        \n",
    "        for W_l, z2_, z1_, z_pr in reversed(list(zip(self.Ws_temp, \n",
    "                                             z2, z1, z_pr))):\n",
    "            \n",
    "            z1_ = z1_*beta_rate.expand(z1_.shape)\n",
    "            diff = z2_ - z_pr #(batchsize, heads, dim_hidden)\n",
    "            diff = diff*(2./ (diff.shape[1]*diff.shape[2]))\n",
    "            W_l = W_l - torch.matmul(diff.transpose(1,2), z1_)#- 0.0001*W_l 0.1\n",
    "            Ws_t.insert(0, W_l)\n",
    "\n",
    "        self.Ws_temp[:] = Ws_t\n",
    "        \n",
    "        # Run memory forward again after memory update \n",
    "        v_w_approx, activations = self.forward(k_w)\n",
    "        reconst_loss = self.mse_loss(v_w_approx.view(-1, v_w_approx.shape[2]), \n",
    "                                      v_w.view(-1, v_w.shape[2]))\n",
    "        \n",
    "        return reconst_loss, reconst_loss_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNMp (Metalearned Neural Memory with local memory updates)\n",
    "\n",
    "As opposed to gradient based updates\n",
    "\n",
    "The embedded sequence x of input vectors x_t is processed sequentially by MNMp as x_t having shape (batch size, n_units) in the order of the sequence. \n",
    "\n",
    "The first neural network that processes the input vector x_t is \n",
    "\n",
    "`self.lstm_l1 = nn.LSTMCell(n_units+n_in_mem, n_units)`\n",
    "\n",
    "where the class parameters are `torch.nn.LSTMCell(input_size, hidden_size, bias=True)`\n",
    "\n",
    "This is because the input to the LSTMCell, a single layer LSTM, is the concatenation of the input x_t with the memory readout vector v_t-1 of shape `(batch size, self.n_in_mem)`\n",
    "\n",
    "The first time that the MNMp forward pass is used, the initial memory readout vector - self.v, and LSTM controller hidden states - self.h_lstm and self.c_lstm is initialized as zero vectors, it is then updated thereafter with each subsequent forward pass x_t.\n",
    "\n",
    "In the paper this LSTM controller is \n",
    "\n",
    "$$h_t = LSTM(x_t, v^{r}_{t-1}, h_{t-1})$$\n",
    "\n",
    "In PyTorch the LSTMCell takes an input and a hidden state (hidden state, cell state) tuple, so this mathematical term appears as \n",
    "\n",
    "`self.h_lstm, self.c_lstm = self.lstm_l1(torch.cat([x, self.v], dim=1), (self.h_lstm, self.c_lstm))`\n",
    "\n",
    "The hidden state output of the LSTM controller is placed through an affine transformation and tanh non-linearity to produce a large vector that is then separated into the interaction vectors.\n",
    "\n",
    "$$[k^{r}_{t,1} . . . k^{r}_{t,H}; k^{w}_{t,1} . . .  k^{w}_{t,H}; v^{w}_{t,1}. . . v^{w}_{t,H}; β'_t] = tanh(W_v h_t + b_v)$$\n",
    "\n",
    "`int_vecs = torch.tanh(self.heads_l2(self.h_lstm))`\n",
    "\n",
    "For each sampled inthe batch, there are H sets of 3 vectors, the read key, write key and write value, plus one rate vector beta_.\n",
    "\n",
    "The rate vector is projected to a scalar \"rate\", called beta in the range 0 to 1. The operation\n",
    "\n",
    "`n_k_v = n_k_v.view(n_k_v.shape[0], self.n_heads, -1).contiguous()`\n",
    "\n",
    "The rate vector is separated from the other interaction vectors in this step, \n",
    "this portion of the interaction vectors n_k_v consists of the write key-value pairs,\n",
    "and the read key, it does not include the read value, because this has to bre read from the memory function using the read key in the `self.v_r = self.memfunc.read(k_r)` step. \n",
    "\n",
    "`\n",
    "beta_,n_k_v=torch.split(int_vecs,[self.dim_hidden,self.dim_hidden*self.n_heads*3],dim=1)\n",
    "`\n",
    "\n",
    "The shape of the n_k_v undergoes these shape changes \n",
    "\n",
    "(batchsize, dim_hidden*n_heads*3)->(batchsize,n_heads,dim_hidden*3)\n",
    "`n_k_v = n_k_v.view(n_k_v.shape[0], self.n_heads, -1).contiguous()`\n",
    "        \n",
    "`k_w, v_w, k_r = torch.chunk(n_k_v, 3, dim=2)`\n",
    "\n",
    "each of these tensors k_w, v_w, k_r is of shape (batchsize, n_heads, dim_hidden)\n",
    "\n",
    "k_w, v_w are passed to the memory update function along with the rate scalar beta. How hte Memory is updated is explained in the FFMemory section\n",
    "\n",
    "`re_const_loss, re_const_loss_init = self.memfunc.update(k_w, v_w, beta_rate=beta)`\n",
    "\n",
    "The controller hidden state is updated using both the previous hidden state and the read value produced from the memory\n",
    "\n",
    "`h_lstm = self.read_out(torch.cat([self.h_lstm, self.v_r], dim=1))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNMp(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, n_heads = 4):\n",
    "        \n",
    "        \"\"\" dim_hidden is the hidden size of the LSTM controller,\n",
    "            the Memory Network, and the interaction vectors\n",
    "            n_heads is the number of interaction heads \"\"\"\n",
    "\n",
    "        super(MNMp, self).__init__()\n",
    "        \n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.control = nn.LSTMCell(dim_hidden*2, dim_hidden)\n",
    "        \n",
    "        dim_concat_interact = dim_hidden*n_heads*3 + dim_hidden\n",
    "        self.interaction = nn.Linear(dim_hidden, dim_concat_interact)\n",
    "        \n",
    "        self.memfunc = FFMemoryLearned(dim_hidden)\n",
    "        \n",
    "        self.kv_rate = nn.Linear(dim_hidden, 1)\n",
    "        \n",
    "        self.read_out = nn.Linear(dim_hidden+dim_hidden, dim_hidden)\n",
    "        \n",
    "        self.v_r = None\n",
    "        self.h_lstm = None\n",
    "        self.c_lstm = None\n",
    "            \n",
    "    def initialize_v_h_c(self, batch_size):\n",
    "        \n",
    "            self.v_r = torch.zeros((batch_size, self.dim_hidden)).float()\n",
    "            self.h_lstm = torch.zeros((batch_size, self.dim_hidden)).float()\n",
    "            self.c_lstm = torch.zeros((batch_size, self.dim_hidden)).float()\n",
    "            \n",
    "            if next(self.parameters()).is_cuda:\n",
    "                self.v_r = self.v_r.cuda()\n",
    "                self.h_lstm = self.h_lstm.cuda()\n",
    "                self.c_lstm = self.c_lstm.cuda()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.initialize_v_h_c(x.shape[0])\n",
    "\n",
    "        self.h_lstm, self.c_lstm = self.control(torch.cat([x, self.v_r], dim=1), \n",
    "                                                (self.h_lstm, self.c_lstm))\n",
    "        \n",
    "        int_vecs = torch.tanh(self.interaction(self.h_lstm))\n",
    "            \n",
    "        \n",
    "        beta_, n_k_v = torch.split(int_vecs, \n",
    "                                   [self.dim_hidden, \n",
    "                                   self.dim_hidden*self.n_heads*3],\n",
    "                                   dim=1)  \n",
    "        \n",
    "        beta = torch.sigmoid(self.kv_rate(beta_)) #(batch_size,1)\n",
    "        \n",
    "        #(batchsize, dim_hidden*n_heads*3)->(batchsize,n_heads,dim_hidden*3)\n",
    "        n_k_v = n_k_v.view(n_k_v.shape[0], self.n_heads, -1).contiguous()\n",
    "        \n",
    "        # each below is shaped (batchsize, n_heads, dim_hidden)\n",
    "        k_w, v_w, k_r = torch.chunk(n_k_v, 3, dim=2)\n",
    "        \n",
    "        # This is the right to memory operation\n",
    "        reconst_loss, reconst_loss_init = self.memfunc.update(k_w, v_w, \n",
    "                                                                beta_rate=beta)\n",
    "        # This is the read from memory operation\n",
    "        self.v_r = self.memfunc.read(k_r)\n",
    "        \n",
    "        h_lstm = self.read_out(torch.cat([self.h_lstm, self.v_r], dim=1))\n",
    "        \n",
    "        return h_lstm, reconst_loss, reconst_loss_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm = MNMp(dim_hidden=8, n_heads=2)\n",
    "\n",
    "embed_idx = nn.Embedding(num_embeddings=test_generator.n_vocab,embedding_dim=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 28  8 29  3 28 15 29  3 28 15 29  9 28 20 29 30 12 28 31]]\n",
      "--------------------\n",
      "[[8]]\n"
     ]
    }
   ],
   "source": [
    "# MNMp sandbox\n",
    "batch = test_generator.next()\n",
    "x = batch[0]\n",
    "y = batch[1]\n",
    "\n",
    "print(x)\n",
    "print(\"--------------------\")\n",
    "print(y)\n",
    "\n",
    "input_x = torch.LongTensor(x) # (batch size, sequence length)\n",
    "input_x = embed_idx(input_x) # (batch size, sequence length, n_units)\n",
    "input_x = torch.chunk(input_x, input_x.shape[1], dim=1) # tuple of size sequence length\n",
    "\n",
    "for x in input_x:\n",
    "    x = x.squeeze(1) #(batch_size, n_units)\n",
    "    h, const_loss, re_const_loss_init = mnm(x)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNMpSeq2Seq \n",
    "\n",
    "The highest level of the model. The train function runs the forward pass of the model. \n",
    "\n",
    "## The Forward Pass\n",
    "\n",
    "the first step is that the sequence token is embedded. In the DictInf class you see that the vocabulary size of the embedding is self.n_alphabet+5 where self.n_alphabet = 26 for the number of characters in the alphabet.  n_units is the hidden size of the embedding. \n",
    "\n",
    "The embedded sequence is processed sequentially by MNMp as shape (batch size, n_units) in the order of the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNMpSeq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, n_vocab, dim_hidden, n_heads):\n",
    "        \n",
    "        super(MNMpSeq2Seq, self).__init__()\n",
    "\n",
    "        self.embed_idx = nn.Embedding(n_vocab, dim_hidden)\n",
    "        self.mnm = MNMp(dim_hidden, n_heads)\n",
    "        self.w_out = nn.Linear(dim_hidden, n_vocab)\n",
    "        \n",
    "        self.n_vocab = n_vocab\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        \n",
    "        self.mnm.memfunc.detach_mem()\n",
    "        \n",
    "        input_x = torch.LongTensor(input_x) # (batch size, sequence length)\n",
    "        \n",
    "        if next(self.parameters()).is_cuda:\n",
    "            input_x = input_x.cuda()\n",
    "            \n",
    "        input_x = self.embed_idx(input_x) # (batch size, sequence length, n_units)\n",
    "        \n",
    "        # tuple of size sequence length where element are shape (batch_size, 1, n_units)\n",
    "        input_x = torch.chunk(input_x, input_x.shape[1], dim=1) \n",
    "        \n",
    "        h_all = []\n",
    "        reconst_loss_all = 0\n",
    "        reconst_loss_init_all = 0\n",
    "        for x in input_x:\n",
    "            x = x.squeeze(1) #(batch_size, dim_hidden)\n",
    "            h_lstm, reconst_loss, reconst_loss_init = self.mnm(x)\n",
    "            reconst_loss_all += reconst_loss\n",
    "            reconst_loss_init_all += reconst_loss_init\n",
    "            h_all.append(h_lstm.unsqueeze(1))\n",
    "\n",
    "        reconst_loss_all /= len(input_x)\n",
    "        reconst_loss_init_all /= len(input_x)\n",
    "        \n",
    "        return h_all, reconst_loss_all, reconst_loss_init_all\n",
    "\n",
    "    def train(self, input_x, trg):\n",
    "\n",
    "        h_all, reconst_loss_all, reconst_loss_init_all = self.forward(input_x)\n",
    "\n",
    "        trg = torch.LongTensor(trg)\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        h = h_all[-trg_len:]\n",
    "        h = torch.cat(h, dim=1)\n",
    "        y = self.w_out(h)\n",
    "        y = torch.transpose(y, 1, 2)\n",
    "        y_preds = y.argmax(1).cpu().numpy()\n",
    "\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            trg = trg.cuda()\n",
    "            \n",
    "        loss = F.cross_entropy(y, trg)\n",
    "\n",
    "        return y_preds, loss, reconst_loss_all, reconst_loss_init_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNMpSeq2Seq(n_vocab=32, dim_hidden=64, n_heads=4)\n",
    "load_model(model,\"modelstate/mnm_64_4_gpu.pth\")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [ 1 11 24 15] [ 1 11 24  9]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [22 20 16 20] [22 20 16 20]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_generator = DictInf(batch_size=64, max_iter=100,\n",
    "#train_generator = DictInf(batch_size=4, max_iter=1,  \n",
    "                          min_num_items=4, max_num_items=4, \n",
    "                          min_item_length=1, max_item_length=1, \n",
    "                          checkpoint=20)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "total_loss = 0\n",
    "total_reconst_loss = 0\n",
    "reconst_loss_init_all = 0\n",
    "total_acc = 0\n",
    "\n",
    "loss_all_list = []\n",
    "acc_list = []\n",
    "\n",
    "train_generator.cur_iter = 0\n",
    "\n",
    "while train_generator.cur_iter <= train_generator.max_iter:\n",
    "    \n",
    "    start = time.time()\n",
    "    batch = train_generator.next()\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "\n",
    "    y_preds, loss, reconst_loss, reconst_loss_init = model.train(x, y)\n",
    "\n",
    "    y_true = y.reshape((-1, ))\n",
    "    y_preds = y_preds.reshape((-1, ))\n",
    "    print(type(y_true), type(y_preds), y_true, y_preds)\n",
    "    acc = accuracy_score(y_true, y_preds)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss_t = loss + reconst_loss\n",
    "    loss_t.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.float().item()\n",
    "    total_reconst_loss += reconst_loss.float().item()\n",
    "    reconst_loss_init_all += reconst_loss_init.float().item()\n",
    "    total_acc += acc\n",
    "\n",
    "    loss_all_list.append(loss.float().item())\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    \n",
    "    if train_generator.cur_iter % train_generator.checkpoint == 0:\n",
    "\n",
    "        print (\"iter: \", train_generator.cur_iter)\n",
    "        print (\"train acc: \", total_acc/train_generator.checkpoint)\n",
    "        print (\"train loss: \", total_loss/train_generator.checkpoint)\n",
    "        print (\"train memory reconst_loss (pre-update):\", \n",
    "               reconst_loss_init_all/train_generator.checkpoint)\n",
    "        print (\"train memory reconst_loss (post-update):\",  \n",
    "               total_reconst_loss/train_generator.checkpoint)\n",
    "        print (\"memory reconst_loss gain:\", \n",
    "               (reconst_loss_init_all - total_reconst_loss)/train_generator.checkpoint)\n",
    "        print(\"runtime\", runtime)\n",
    "        total_loss = 0\n",
    "        total_reconst_loss = 0\n",
    "        reconst_loss_init_all = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "plt.figure()\n",
    "plt.xlabel('Epochs', fontsize=25)\n",
    "plt.ylabel('Loss', fontsize=20)\n",
    "plt.plot(loss_all_list, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,\"modelstate/mnm_64_4_gpu.pth\")\n",
    "model = model.cpu()      \n",
    "save_model(model,\"modelstate/mnm_64_4_cpu.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MNMpSeq2Seq(n_vocab=32, dim_hidden=64, n_heads=4)\n",
    "load_model(model2,\"modelstate/mnm_64_4_cpu.pth\")\n",
    "model2 = model2.cuda()\n",
    "model2.mnm.memfunc.Ws = model.mnm.memfunc.Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.84375\n",
      "loss tensor(0.5993, device='cuda:0')\n",
      "tensor(0.5642, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(0.1345, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = train_generator.next()\n",
    "x = batch[0]\n",
    "y = batch[1]\n",
    "\n",
    "y_preds2, loss2, reconst_loss2, reconst_loss_init2 = model2.train(x, y)\n",
    "#y_preds, loss, reconst_loss, reconst_loss_init = model.train(x, y)\n",
    "\n",
    "y_true = y.reshape((-1, ))\n",
    "y_preds2 = y_preds2.reshape((-1, ))\n",
    "acc = accuracy_score(y_true, y_preds2)\n",
    "\n",
    "print(\"accuracy\",acc)\n",
    "print(\"loss\", loss_t.data)\n",
    "print(loss2.data, reconst_loss2.data, reconst_loss_init2.data)\n",
    "#print(loss.data, reconst_loss.data, reconst_loss_init.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_idx.weight\n",
      "mnm.control.weight_ih\n",
      "mnm.control.weight_hh\n",
      "mnm.control.bias_ih\n",
      "mnm.control.bias_hh\n",
      "mnm.interaction.weight\n",
      "mnm.interaction.bias\n",
      "mnm.memfunc.expected_activation.weight\n",
      "mnm.memfunc.expected_activation.bias\n",
      "mnm.kv_rate.weight\n",
      "mnm.kv_rate.bias\n",
      "mnm.read_out.weight\n",
      "mnm.read_out.bias\n",
      "w_out.weight\n",
      "w_out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
